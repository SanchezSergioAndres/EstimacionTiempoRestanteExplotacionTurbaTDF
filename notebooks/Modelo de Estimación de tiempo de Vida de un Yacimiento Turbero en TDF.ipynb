{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Materia**: Aprendizaje Automático\n",
        "## **Año**: 2025 - 1º Cuatrimestre\n",
        "### **Alumno**: SANCHEZ Sergio Andrés"
      ],
      "metadata": {
        "id": "g0rKWawVzr2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentación de Objetivo del Proyecto"
      ],
      "metadata": {
        "id": "r-rjh-DXvxUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollar un modelo de Aprendizaje Automático que permita estimar el tiempo de vida restante de explotación de un yacimiento de turba en Tierra del Fuego, promoviendo una gestión sostenible del recurso.\n",
        "\n",
        "El problema que se busca resolver es de regresión, ya que la variable objetivo será una estimación continua del tiempo (en meses, años o décadas) restante hasta que se agote el yacimiento, en función del volumen total estimado de turba y del ritmo de extracción y comercialización histórico.\n"
      ],
      "metadata": {
        "id": "VVoCeoyov8Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importancia y Relevancia del problema abordado"
      ],
      "metadata": {
        "id": "N_udDnWtwGFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La extracción de turba en la provincia de Tierra del Fuego representa una actividad productiva clave, especialmente en zonas rurales. La turba es un recurso natural no renovable en escalas humanas de tiempo y su extracción está condicionada por factores climáticos, estacionales y económicos.\n",
        "\n",
        "Con una estacionalidad marcada (más actividad en verano que en invierno), la explotación turbera requiere una planificación precisa para evitar la sobreexplotación y promover la sostenibilidad del recurso. Actualmente, las decisiones sobre tiempos de explotación se basan en cálculos aproximados o estimaciones estáticas. Un modelo predictivo que estime cuánto tiempo resta de explotación puede apoyar políticas públicas, decisiones empresariales y controles ambientales.\n"
      ],
      "metadata": {
        "id": "kTkQ6668wL9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descripción del Dataset"
      ],
      "metadata": {
        "id": "9lSgtFGKwVnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Origen:** El Dataset proviene de una base de datos en Postgre de la Dirección General de Desarrollo Minero dependiente del Ministerio de Producción y Ambiente del Gobierno de la Provincia de Tierra del Fuego, Antártida e Islas del Atlántico Sur.\n",
        "\n",
        "**Fecha de disponibilidad del Dataset:** Viernes 06 de junio de 2025 – Segunda Versión Dataset.\n",
        "\n",
        "El Dataset provisto contempla expedientes tramitados por explotación de Turba Rubia y Negra por cada uno de los yacimientos desde enero de 2020 a diciembre de 2024.\n",
        "\n",
        "Este Dataset cuenta con 1635 filas y 27 columnas con las siguientes características:\n",
        "\n",
        "| Variable               | Tipo        | Definición                                                                 |\n",
        "|------------------------|-------------|---------------------------------------------------------------------------|\n",
        "| Area                  | Numérica    | Superficie del yacimiento, en hectáreas                                   |\n",
        "| Vol_N                 | Numérica    | Volumen de turba negra a 2023                                             |\n",
        "| Vol_R                 | Numérica    | Volumen de turba rubia a 2023                                             |\n",
        "| Vol_total             | Numérica    | Volumen total de turba a 2023                                             |\n",
        "| Fecha                 | Numérica    | Año de cuantificación (2023)                                              |\n",
        "| id                    | Numérica    | valor de identificación (no tener en cuenta)                              |\n",
        "| _uid_                 | Numérica    | valor de identificación (no tener en cuenta)                              |\n",
        "| poligono              | Numérica    | número del polígono                                                       |\n",
        "| id_2                  | Numérica    | valor de identificación (no tener en cuenta)                              |\n",
        "| producto              | Categórica  | tipo de mineral extraído                                                  |\n",
        "| num_expte             | Numérica    | número de expediente de regalías mineras                                  |\n",
        "| ano                   | Numérica    | año de declaración jurada                                                 |\n",
        "| mes                   | Numérica    | mes de declaración jurada                                                 |\n",
        "| volumen_produccion    | Numérica    | volumen de mineral extraído                                               |\n",
        "| trimestre             | Numérica    | trimestre de la declaración jurada                                        |\n",
        "| regalias              | Numérica    | importe de regalías mineras liquidado                                     |\n",
        "| tasa_insp_fisc        | Numérica    | importe de tasas de fiscalización liquidado                               |\n",
        "| ano_comer             | Numérica    | año de comercialización territorio nacional continental                    |\n",
        "| mes_comer             | Numérica    | mes de comercialización a territorio nacional continental                  |\n",
        "| productor_comer       | Numérica    | número de productor                                                       |\n",
        "| producto_comer        | Numérica    | producto comercializado                                                   |\n",
        "| volumen_comercializado| Numérica    | volumen comercializado                                                    |\n",
        "| valor_fob_usd         | Numérica    | valor FOB expresado en dólares (valor de mineral puesto en aduana)        |\n",
        "| valor_fob_ars         | Numérica    | valor FOB expresado en pesos (valor de mineral puesto en aduana)          |\n",
        "| tasas_comercial       | Numérica    | tasas abonadas por emisión de certificado de exportación                  |\n",
        "| tasa_cambio           | Numérica    | relación peso/dólar al emitir el certificado de exportación               |\n",
        "| sin_comercializacion  | Categórica  | valor TRUE (no comercializó) o FALSE (comercializó)\n",
        "\n",
        "De este Dataset anonimizado, se estimará el tiempo de vida de cada uno de los yacimientos en base a saber su volumen total actual y las extracciones realizadas en los periodos que van desde Enero 2020 a Diciembre 2024 (5 años exactos).\n",
        "\n",
        "Para el análisis a realizar, tendremos en cuenta solo aquellos yacimientos que han tenido producción en el periodo mencionado, es decir, que hayan tenido o estén en actividad informada.\n"
      ],
      "metadata": {
        "id": "oJkUVfMiwXrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desarrollo del Modelo\n"
      ],
      "metadata": {
        "id": "0zxNPPQ7yu4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este modelo se utilizó:\n",
        "\n",
        "* Algoritmo: Random Forest Regressor\n",
        "* Tipo de Modelo: Aprendizaje supervisado, Regresión\n",
        "* Variable Objetivo: meses_restantes_estimados (vida útil en meses)\n",
        "* Variable predictora principal: extraccion_prom_mensual (media móvil de extracción de los últimos 6 meses).\n",
        "* Transformación aplicada: Log-transformación de la variable objetivo para estabilizar la varianza y mejorar la distribución."
      ],
      "metadata": {
        "id": "olXBt23XzGoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperparámetros utilizados"
      ],
      "metadata": {
        "id": "2SIqEvWpzIw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* n_estimators = 100: número de árboles en el bosque.\n",
        "* random_state = 42: para reproducibilidad.\n",
        "\n",
        "Se utilizó el valor por defecto de max_depth para permitir que cada árbol crezca libremente, maximizando el ajuste local.\n"
      ],
      "metadata": {
        "id": "J4e7shiXzNpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas utilizadas para evaluar el modelo"
      ],
      "metadata": {
        "id": "XUbmIuzAzR_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **MAE** (Error Absoluto Medio)\n",
        "* **RMSE** (Raíz del Error Cuadrático Medio)\n",
        "* **R2** (Coeficiente de Determinación)"
      ],
      "metadata": {
        "id": "h_aKSsH4zXhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importación de Librerías"
      ],
      "metadata": {
        "id": "fxOZyDmuzhAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTACIÓN DE LIBRERÍAS ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "n91cvfGsbw8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Datos"
      ],
      "metadata": {
        "id": "Cl4a6VGBzmMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CARGA DE DATOS ---\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ruta = \"/content/drive/My Drive/CPSMA/2025/Parcial/dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(ruta, sep=\";\")"
      ],
      "metadata": {
        "id": "dx3TZAEPbt8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardo una copia del DataFrame original"
      ],
      "metadata": {
        "id": "b_dYNCF0zp6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardo una copia del DataFrame original\n",
        "df_original = df.copy()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "mw5F6xXMcFce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpieza de Datos"
      ],
      "metadata": {
        "id": "yf60YBppyPXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimino las columnas que no voy a utilizar\n",
        "\n",
        "df = df.drop(columns=[\"Fecha\", \"id\", \"_uid_\", \"id_2\", \"producto\", \"num_expte\", \"trimestre\", \"regalias\",\n",
        "                      \"tasa_insp_fisc\", \"ano_comer\", \"mes_comer\", \"productor_comer\",\n",
        "                      \"producto_comer\", \"volumen_comercializado\", \"valor_fob_usd\", \"valor_fob_ars\",\n",
        "                      \"tasas_comercial\", \"tasa_cambio\", \"sin_comercializacion\"])\n",
        "\n",
        "\n",
        "df.info()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "bGcZ182xR_Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ Limpio filas por poligono vacio ------------\n",
        "\n",
        "# Filtro las filas que serán eliminadas (donde 'poligono' está vacío o NaN)\n",
        "filas_a_eliminar = df[df[\"poligono\"].isna()]\n",
        "\n",
        "# Reemplazo strings vacíos por NaN\n",
        "df[\"poligono\"] = df[\"poligono\"].replace('', np.nan)\n",
        "\n",
        "# Muestro las filas que serán eliminadas\n",
        "print(\"Filas que serán eliminadas (por 'poligono' en blanco o NaN):\")\n",
        "display(filas_a_eliminar)\n",
        "\n",
        "# Elimino las filas del DataFrame original\n",
        "df = df.dropna(subset=[\"poligono\"])\n",
        "\n",
        "# Muestro la cantidad de filas eliminadas\n",
        "print(f\"\\nTotal de filas eliminadas: {len(filas_a_eliminar)}\")\n",
        "\n",
        "# Confirmo cuántas filas quedan\n",
        "print(f\"\\nFilas restantes luego de limpieza: {len(df)}\")\n",
        "\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "f4uGH6EQbE44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso los object a FLOAT\n",
        "\n",
        "# Me aseguro de tener los tipos de datos que corresponde en cada característica\n",
        "\n",
        "# Hago una copia por seguridad antes de trabajar y evitar Warnings\n",
        "df = df.copy()\n",
        "\n",
        "# Ver todas las columnas de tipo object\n",
        "df.select_dtypes(include='object').columns\n",
        "\n",
        "cols_a_convertir = [\"Area\", \"Vol_N\", \"Vol_R\", \"Vol_total\", \"volumen_produccion\"]\n",
        "for col in cols_a_convertir:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "        .astype(str)\n",
        "        .str.replace(\",\", \".\", regex=False)\n",
        "    )\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "# Verificación final de los tipos de datos\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "zc4TYzJlgJ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierto columnas \"poligono\", \"ano\", \"mes\" a enteros\n",
        "columnas_enteras = [\"poligono\", \"ano\", \"mes\"]\n",
        "for col in columnas_enteras:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "# Verificación final de los tipos de datos\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "P6-WIyQTejyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ypv8d4ZXRdrJ"
      },
      "outputs": [],
      "source": [
        "# Creo columnas de fecha\n",
        "df[\"fecha\"] = pd.to_datetime(\n",
        "    df[\"ano\"].astype(str) + \"-\" + df[\"mes\"].astype(str).str.zfill(2),\n",
        "    format=\"%Y-%m\",\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "df[\"ano_mes\"] = df[\"fecha\"].dt.to_period(\"M\")\n",
        "\n",
        "# Verificación final de los tipos de datos\n",
        "print(df.dtypes)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ Limpio filas por volumen_produccion = 0  ------------\n",
        "\n",
        "# Filtro las filas que serán eliminadas (donde 'volumen_produccion' = 0)\n",
        "\n",
        "# Cantidad de Filas Antes de la limpieza\n",
        "filas_antes = df.shape[0]\n",
        "\n",
        "# Filtro y dejo solo las que volumen_produccion = 0\n",
        "df = df[df[\"volumen_produccion\"] != 0.0]\n",
        "\n",
        "# Cantidad de Filas después de la limpieza\n",
        "filas_despues = df.shape[0]\n",
        "\n",
        "print(f\"Filas eliminadas: {filas_antes - filas_despues}\")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "nYg41oYDeXKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detección de outliers en volumen_produccion con IQR y decidir si eliminarlos o transformarlos\n",
        "\n",
        "Q1 = df[\"volumen_produccion\"].quantile(0.25)\n",
        "Q3 = df[\"volumen_produccion\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "limite_inferior = Q1 - 1.5 * IQR\n",
        "limite_superior = Q3 + 1.5 * IQR\n",
        "df_cleaned = df[(df[\"volumen_produccion\"] >= limite_inferior) & (df[\"volumen_produccion\"] <= limite_superior)]"
      ],
      "metadata": {
        "id": "C_GDDEZ_fhlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestro valor de cada dato obtenido\n",
        "\n",
        "print(\"Q1 (25%):\", Q1)\n",
        "print(\"Q3 (75%):\", Q3)\n",
        "print(\"IQR:\", IQR)\n",
        "print(\"Límite inferior:\", limite_inferior)\n",
        "print(\"Límite superior:\", limite_superior)"
      ],
      "metadata": {
        "id": "q6JofFFvgDvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizo los outliers (Antes de eliminar)\n",
        "\n",
        "\n",
        "sns.boxplot(data=df, y=\"volumen_produccion\")\n",
        "plt.title(\"Boxplot de volumen_produccion (Antes de eliminar Outliers)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bjp4KOUff23R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimino Outliers\n",
        "\n",
        "outliers = df_cleaned = df[(df[\"volumen_produccion\"] >= limite_inferior) & (df[\"volumen_produccion\"] <= limite_superior)]\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "98aKoM3Pgp1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizo outliers (Después de eliminar)\n",
        "\n",
        "sns.boxplot(data=df_cleaned, y=\"volumen_produccion\")\n",
        "plt.title(\"Boxplot de Ingresos (Después de eliminar Outliers)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W8vsd7_Dgtcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copio el Dataframe de limpieza al Dataframe df\n",
        "df = df_cleaned.copy()"
      ],
      "metadata": {
        "id": "teE8_dIghkoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AGRUPACIÓN POR POLÍGONO Y MES ---\n",
        "df_prod = df.groupby([\"poligono\", \"ano_mes\"]).agg({\n",
        "    \"volumen_produccion\": \"sum\",\n",
        "    \"Area\": \"first\",\n",
        "    \"Vol_N\": \"first\",\n",
        "    \"Vol_R\": \"first\",\n",
        "    \"Vol_total\": \"first\"\n",
        "}).reset_index()\n",
        "\n",
        "# Cálculo de extracción acumulada\n",
        "df_prod[\"volumen_acumulado\"] = df_prod.groupby(\"poligono\")[\"volumen_produccion\"].cumsum()\n",
        "\n",
        "# Cálculo de volumen restante\n",
        "df_prod[\"volumen_restante\"] = df_prod[\"Vol_total\"] - df_prod[\"volumen_acumulado\"]\n",
        "\n",
        "# Promedio móvil de extracción\n",
        "df_prod[\"extraccion_prom_mensual\"] = df_prod.groupby(\"poligono\")[\"volumen_produccion\"].transform(lambda x: x.rolling(window=6, min_periods=1).mean())\n",
        "\n",
        "# Reemplazo 0 por NaN antes del cálculo\n",
        "df_prod.loc[df_prod[\"extraccion_prom_mensual\"] == 0, \"extraccion_prom_mensual\"] = np.nan\n",
        "\n",
        "# Estimo meses restantes (evita división por cero)\n",
        "df_prod[\"meses_restantes_estimados\"] = df_prod[\"volumen_restante\"] / df_prod[\"extraccion_prom_mensual\"]\n",
        "df_prod[\"meses_restantes_estimados\"] = df_prod[\"meses_restantes_estimados\"].clip(lower=0)\n",
        "\n",
        "# Elimino las filas del DataFrame produccion\n",
        "df_prod = df_prod.dropna(subset=[\"extraccion_prom_mensual\"])\n",
        "\n",
        "df_prod"
      ],
      "metadata": {
        "id": "m2CHF2QOSFut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazo 0 en extraccion_prom_mensual por NaN\n",
        "df_prod.loc[df_prod[\"extraccion_prom_mensual\"] == 0, \"extraccion_prom_mensual\"] = np.nan"
      ],
      "metadata": {
        "id": "9mt1ZxoS1LRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construyo el Modelo - RandomForestRegressor"
      ],
      "metadata": {
        "id": "lYl6zvk51Mc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONSTRUCCIÓN DEL MODELO ---\n",
        "df_modelo = df_prod.dropna(subset=[\"meses_restantes_estimados\", \"extraccion_prom_mensual\"])\n",
        "X = df_modelo[[\"Area\", \"Vol_N\", \"Vol_R\", \"Vol_total\", \"extraccion_prom_mensual\"]]\n",
        "y = df_modelo[\"meses_restantes_estimados\"]\n",
        "\n",
        "print(f\"Filas en X: {len(X)}\")\n",
        "print(f\"Filas en y: {len(y)}\")\n",
        "print(\"¿Hay valores nulos en X?\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "print(\"Valores nulos en 'extraccion_prom_mensual':\", df_prod[\"extraccion_prom_mensual\"].isna().sum())\n",
        "\n",
        "print(\"Valores nulos en 'meses_restantes_estimados':\", df_prod[\"meses_restantes_estimados\"].isna().sum())\n",
        "\n",
        "print(\"Tamaño de df_prod:\", df_prod.shape)\n",
        "print(\"Tamaño de df_modelo antes de dropna:\", df_prod[[\"meses_restantes_estimados\", \"extraccion_prom_mensual\"]].shape)\n",
        "\n",
        "# División entrenamiento / prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Confirmar que X e y no tengan NaN\n",
        "print(\"¿Hay NaN en X?\", X.isna().sum())\n",
        "print(\"¿Hay NaN en y?\", y.isna().sum())\n",
        "\n",
        "# Entrenar modelo\n",
        "modelo = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Predicción\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "#rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "gIFCQdzAbFqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importancia de atributos\n",
        "importancias = pd.Series(modelo.feature_importances_, index=X.columns)\n",
        "importancias.sort_values(ascending=True).plot(kind=\"barh\")\n",
        "plt.title(\"Importancia de Atributos\")\n",
        "plt.show()\n",
        "\n",
        "# Guardar resultados\n",
        "df_modelo[\"meses_estimados_modelo\"] = modelo.predict(X)\n",
        "df_modelo.to_csv(\"predicciones_vida_util.csv\", index=False)"
      ],
      "metadata": {
        "id": "yfI3vpnN3Ydr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizar errores del modelo - Calidad de las predicciones\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.title(\"Real vs. Predicho\")\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # línea ideal\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1gYMmMZH3is_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizo los polígonos extremos\n",
        "df_modelo[\"error_meses\"] = abs(df_modelo[\"meses_restantes_estimados\"] - df_modelo[\"meses_estimados_modelo\"])\n",
        "df_modelo.sort_values(\"error_meses\", ascending=False).head(10)"
      ],
      "metadata": {
        "id": "qTiEIcpU3njv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polígonos con más registros\n",
        "poligonos_mas_datos = df_prod[\"poligono\"].value_counts().head(5).index.tolist()\n",
        "print(\"Polígonos con más datos:\", poligonos_mas_datos)"
      ],
      "metadata": {
        "id": "1ZIyYpT0k_9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizo el impacto\n",
        "df_modelo[[\"meses_restantes_estimados\", \"meses_estimados_modelo\", \"error_meses\"]].describe()"
      ],
      "metadata": {
        "id": "7kOG65X6pB3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla resumén por polígono\n",
        "\n",
        "# Tomar el último registro de cada polígono\n",
        "vida_util_por_poligono = df_modelo.sort_values(\"ano_mes\").groupby(\"poligono\").tail(1)\n",
        "\n",
        "# Seleccionar columnas relevantes\n",
        "vida_util_por_poligono = vida_util_por_poligono[[\"poligono\", \"ano_mes\", \"volumen_restante\", \"extraccion_prom_mensual\", \"meses_restantes_estimados\", \"meses_estimados_modelo\", \"error_meses\"]]\n",
        "\n",
        "# Ordenar de mayor a menor estimación\n",
        "vida_util_por_poligono = vida_util_por_poligono.sort_values(\"poligono\", ascending=True)\n",
        "\n",
        "# Mostrar\n",
        "vida_util_por_poligono"
      ],
      "metadata": {
        "id": "Ca1SAYetpcha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Barras Vertical (Ordenado por poligono)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "vida_util_por_poligono_plot = vida_util_por_poligono.sort_values(\"poligono\", ascending=True)\n",
        "\n",
        "plt.bar(vida_util_por_poligono_plot[\"poligono\"].astype(str),\n",
        "        vida_util_por_poligono_plot[\"meses_estimados_modelo\"],\n",
        "        color='skyblue')\n",
        "\n",
        "plt.ylabel(\"Meses estimados restantes\")\n",
        "plt.xlabel(\"Polígono\")\n",
        "plt.title(\"Estimación de vida útil de yacimientos (por polígono)\")\n",
        "plt.xticks(rotation=90)  # Rotar etiquetas si son muchas\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fb5wBDC21KTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Barras Horizontal (Ordenado por meses_estimados_modelo)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "vida_util_por_poligono_plot = vida_util_por_poligono.sort_values(\"meses_estimados_modelo\", ascending=True)\n",
        "\n",
        "plt.bar(vida_util_por_poligono_plot[\"poligono\"].astype(str),\n",
        "         vida_util_por_poligono_plot[\"meses_estimados_modelo\"],\n",
        "         color='skyblue')\n",
        "\n",
        "plt.ylabel(\"Meses estimados restantes\")\n",
        "plt.xlabel(\"Polígono\")\n",
        "plt.title(\"Estimación de vida útil de yacimientos (por polígono)\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "llt8649qtM55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar para un polígono\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "def graficar_poligono(df, poligono_id):\n",
        "    df_pol = df[df[\"poligono\"] == poligono_id].sort_values(\"ano_mes\")\n",
        "    df_pol[\"fecha_dt\"] = df_pol[\"ano_mes\"].dt.to_timestamp()\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
        "\n",
        "    # Eje 1: Volumen de producción\n",
        "    ax1.plot(df_pol[\"fecha_dt\"], df_pol[\"volumen_produccion\"], label=\"Volumen de Producción\", color=\"tab:blue\")\n",
        "    ax1.plot(df_pol[\"fecha_dt\"], df_pol[\"extraccion_prom_mensual\"], label=\"Extracción Promedio (6M)\", color=\"tab:cyan\", linestyle=\"--\")\n",
        "    ax1.set_ylabel(\"Volumen (m³)\", color=\"tab:blue\")\n",
        "    ax1.tick_params(axis='y', labelcolor=\"tab:blue\")\n",
        "\n",
        "    # Formato de fechas\n",
        "    ax1.xaxis.set_major_locator(mdates.YearLocator())\n",
        "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Eje 2: Meses restantes\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(df_pol[\"fecha_dt\"], df_pol[\"meses_restantes_estimados\"], label=\"Meses Restantes Estimados\", color=\"tab:red\")\n",
        "    ax2.set_ylabel(\"Meses restantes\", color=\"tab:red\")\n",
        "    ax2.tick_params(axis='y', labelcolor=\"tab:red\")\n",
        "\n",
        "    # Título y leyendas\n",
        "    plt.title(f\"Evolución de Extracción y Vida Útil Estimada - Polígono {poligono_id}\")\n",
        "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.9))\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Elegí uno de los polígonos con más datos\n",
        "graficar_poligono(df_prod, poligonos_mas_datos[0])"
      ],
      "metadata": {
        "id": "1Vwx9fbLlh4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas de la variable objetivo\n",
        "print(df_modelo[\"meses_restantes_estimados\"].describe())\n",
        "\n",
        "# Histograma para ver la distribución\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(df_modelo[\"meses_restantes_estimados\"], bins=30, edgecolor='k')\n",
        "plt.title(\"Distribución de Meses Restantes Estimados\")\n",
        "plt.xlabel(\"Meses restantes\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "195spNV3w-95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box-Plot Horizontal de la característica \"meses_restantes_estimados\"\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.boxplot(df_modelo[\"meses_restantes_estimados\"], vert=False)\n",
        "plt.title(\"Boxplot de Meses Restantes Estimados\")\n",
        "plt.xlabel(\"Meses restantes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cLRmYsNCxFK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saco medidas para observar los outliers y elimanr los innecesarios\n",
        "Q1 = df_modelo[\"meses_restantes_estimados\"].quantile(0.25)\n",
        "Q3 = df_modelo[\"meses_restantes_estimados\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "limite_inf = Q1 - 1.5 * IQR\n",
        "limite_sup = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df_modelo[\n",
        "    (df_modelo[\"meses_restantes_estimados\"] < limite_inf) |\n",
        "    (df_modelo[\"meses_restantes_estimados\"] > limite_sup)\n",
        "]\n",
        "print(f\"Outliers detectados: {len(outliers)} filas\")\n",
        "display(outliers.head())"
      ],
      "metadata": {
        "id": "CP8Ie_rTxKwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro las filas que NO son outliers\n",
        "df_modelo_sin_outliers = df_modelo[\n",
        "    (df_modelo[\"meses_restantes_estimados\"] >= limite_inf) &\n",
        "    (df_modelo[\"meses_restantes_estimados\"] <= limite_sup)\n",
        "]\n",
        "\n",
        "# Confirmo la cantidad de filas después de la limpieza\n",
        "print(f\"Filas sin outliers: {len(df_modelo_sin_outliers)}\")\n",
        "\n",
        "# Reemplazo el DataFrame original y lo dejo sin los outliers\n",
        "df_modelo = df_modelo_sin_outliers.copy()"
      ],
      "metadata": {
        "id": "qbhPasdSvUFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genero el Modelo por Transformación Logarítmica"
      ],
      "metadata": {
        "id": "pqJudzVW4TPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Transformación logarítmica (añado 1 para evitar log(0))\n",
        "df_modelo[\"meses_log\"] = np.log1p(df_modelo[\"meses_restantes_estimados\"])\n",
        "\n",
        "# Volver a entrenar con y = meses_log en lugar de meses_restantes_estimados\n",
        "X = df_modelo[[\"extraccion_prom_mensual\"]]\n",
        "y_log = df_modelo[\"meses_log\"]\n",
        "\n",
        "modelo_log = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "modelo_log.fit(X, y_log)\n",
        "\n",
        "# Predecir y volver a transformar la predicción\n",
        "pred_log = modelo_log.predict(X)\n",
        "pred_unlog = np.expm1(pred_log)\n",
        "\n",
        "# Calcular MAE en la escala original\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae_unlog = mean_absolute_error(\n",
        "    df_modelo[\"meses_restantes_estimados\"],\n",
        "    pred_unlog\n",
        ")\n",
        "print(\"MAE después de log-transform & back-transform:\", mae_unlog)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calcular RMSE en la escala original\n",
        "rmse_unlog = np.sqrt(mean_squared_error(\n",
        "    df_modelo[\"meses_restantes_estimados\"],\n",
        "    pred_unlog\n",
        "))\n",
        "print(\"RMSE después de log-transform & back-transform:\", rmse_unlog)\n",
        "\n",
        "# Después de calcular pred_unlog y asignarlo a df_modelo[\"meses_estimados_log_modelo\"]\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_original = r2_score(df_modelo[\"meses_restantes_estimados\"], df_modelo[\"meses_estimados_modelo\"])\n",
        "df_modelo[\"meses_estimados_log_modelo\"] = pred_unlog\n",
        "r2_log = r2_score(df_modelo[\"meses_restantes_estimados\"], df_modelo[\"meses_estimados_log_modelo\"])\n",
        "\n",
        "print(f\"R² para predicción log-transformada y revertida: {r2_log:.4f}\")"
      ],
      "metadata": {
        "id": "Mob-3JjExQyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien parecen mejorar tanto en MAE como en RMSE, el R2 empeoró muchísimo."
      ],
      "metadata": {
        "id": "QZVvkKpc_71v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla resumén por polígono\n",
        "\n",
        "# Crear columna de predicción revertida\n",
        "df_modelo[\"meses_estimados_log_modelo\"] = pred_unlog\n",
        "\n",
        "# Calcular el error absoluto\n",
        "df_modelo[\"error_log\"] = abs(df_modelo[\"meses_restantes_estimados\"] - df_modelo[\"meses_estimados_log_modelo\"])\n",
        "\n",
        "# Seleccionar columnas clave para el resumen\n",
        "resumen_log = df_modelo[[\n",
        "    \"poligono\", \"volumen_restante\", \"extraccion_prom_mensual\",\n",
        "    \"meses_restantes_estimados\", \"meses_estimados_log_modelo\", \"error_log\"\n",
        "]]\n",
        "\n",
        "# Ordenar por número de polígono en orden ascendente\n",
        "resumen_log = resumen_log.sort_values(by=\"error_log\", ascending=True)\n",
        "\n",
        "# Mostrar la tabla\n",
        "display(resumen_log)"
      ],
      "metadata": {
        "id": "WN7wxzjevg84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomar el último registro de cada polígono\n",
        "vida_util_log_por_poligono = df_modelo.sort_values(\"ano_mes\").groupby(\"poligono\").tail(1)\n",
        "\n",
        "# Seleccionar columnas relevantes\n",
        "vida_util_log_por_poligono = vida_util_log_por_poligono[[\n",
        "    \"poligono\", \"ano_mes\", \"volumen_restante\", \"extraccion_prom_mensual\",\n",
        "    \"meses_restantes_estimados\", \"meses_estimados_log_modelo\", \"error_log\"\n",
        "]]\n",
        "\n",
        "# Ordenar de mayor a menor por número de polígono\n",
        "vida_util_log_por_poligono = vida_util_log_por_poligono.sort_values(\"poligono\", ascending=True)\n",
        "\n",
        "# Mostrar tabla\n",
        "display(vida_util_log_por_poligono)"
      ],
      "metadata": {
        "id": "a0Y-q28IyuJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aparte de haber empeorado muchísimo el R², también tengo 2 polígonos menos (3 y 18)."
      ],
      "metadata": {
        "id": "znd0N7u6Ac_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear una nueva columna con rangos de meses\n",
        "df_modelo[\"rango_meses\"] = pd.cut(\n",
        "    df_modelo[\"meses_restantes_estimados\"],\n",
        "    bins=[0, 100, 500, 1000, 5000, 10000, np.inf],\n",
        "    labels=[\"0-100\", \"100-500\", \"500-1000\", \"1000-5000\", \"5000-10000\", \"10000+\"]\n",
        ")\n",
        "\n",
        "# Calcular errores de ambos modelos\n",
        "df_modelo[\"error_original\"] = abs(df_modelo[\"meses_restantes_estimados\"] - df_modelo[\"meses_estimados_modelo\"])\n",
        "df_modelo[\"error_log\"] = abs(df_modelo[\"meses_restantes_estimados\"] - df_modelo[\"meses_estimados_log_modelo\"])\n",
        "\n",
        "# Agrupar por rango y calcular estadísticas\n",
        "comparacion = df_modelo.groupby(\"rango_meses\", observed=False).agg({\n",
        "    \"error_original\": [\"mean\", \"median\", \"count\"],\n",
        "    \"error_log\": [\"mean\", \"median\"]\n",
        "}).reset_index()\n",
        "\n",
        "# Renombrar columnas para claridad\n",
        "comparacion.columns = [\n",
        "    \"Rango de meses\",\n",
        "    \"MAE original (media)\",\n",
        "    \"Mediana error original\",\n",
        "    \"Cantidad\",\n",
        "    \"MAE log-transform\",\n",
        "    \"Mediana error log\"\n",
        "]\n",
        "\n",
        "# Mostrar la tabla comparativa\n",
        "display(comparacion)"
      ],
      "metadata": {
        "id": "0P8Gy-gM8DqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definimos los rangos de meses restantes\n",
        "bins = [0, 100, 500, 1000, 5000, 10000, np.inf]\n",
        "labels = [\"0-100\", \"100-500\", \"500-1000\", \"1000-5000\", \"5000-10000\", \"10000+\"]\n",
        "\n",
        "# Clasificamos cada fila según su rango de meses restantes\n",
        "df_modelo[\"rango_meses\"] = pd.cut(df_modelo[\"meses_restantes_estimados\"], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calculamos MAE por rango para modelo original\n",
        "mae_original = df_modelo.groupby(\"rango_meses\", observed=False)[\"error_meses\"].mean()\n",
        "\n",
        "# Calculamos MAE por rango para modelo log-transform\n",
        "mae_log = df_modelo.groupby(\"rango_meses\", observed=False)[\"error_log\"].mean()\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "bars1 = plt.bar(x - width/2, mae_original, width, label='MAE Original', color='steelblue')\n",
        "bars2 = plt.bar(x + width/2, mae_log, width, label='MAE Log-Transform', color='darkorange')\n",
        "\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Rango de Meses')\n",
        "plt.title('Comparación de MAE por Rango de Meses Estimados')\n",
        "plt.xticks(x, labels)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Mostrar valores numéricos encima de cada barra\n",
        "for i in range(len(x)):\n",
        "    plt.text(x[i] - width/2, mae_original.iloc[i] + 30, f\"{mae_original.iloc[i]:.0f}\", ha='center', fontsize=9)\n",
        "    plt.text(x[i] + width/2, mae_log.iloc[i] + 30, f\"{mae_log.iloc[i]:.0f}\", ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h6ubVlYZ9ex9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este gráfico se puede observar para concluir que:\n",
        "\n",
        "*\tPara los rangos bajos (0-100, 100-500, etc.), el modelo original tiene errores mucho menores que el modelo log-transformado.\n",
        "*\tA medida que aumenta el rango, especialmente desde los 1000 meses en adelante, el modelo log-transformado comienza a producir errores mucho mayores.\n",
        "\n",
        "l Modelo de Transformación Logarítmica  puede suavizar la influencia de valores extremos en el entrenamiento, pero al revertirla puede amplificar los errores en las predicciones grandes. Esto sugiere que el modelo original está mejor calibrado para todo el rango, especialmente para valores grandes, mientras que el log-transformado puede no estar capturando correctamente la magnitud de las predicciones en rangos altos.\n"
      ],
      "metadata": {
        "id": "SHW-ve_VA8YA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión Final"
      ],
      "metadata": {
        "id": "Kdqsf9xMBQar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo de Random Forest Regressor sin transformación logarítmica fue el que presentó el mejor rendimiento global, con un R² de 0.96, lo que indica una excelente capacidad explicativa de la variabilidad de los datos. Además, mostró un error absoluto medio (MAE) de aproximadamente 837 meses y un RMSE de 3840, valores coherentes con la escala y dispersión de la variable objetivo.\n",
        "\n",
        "Por otro lado, el modelo con transformación logarítmica logró un MAE más bajo (711) y una notable reducción del RMSE (1432), pero a costa de una fuerte caída en el R² (0.57). Esta baja en el poder explicativo, sumada al análisis por rangos de meses restantes, donde el modelo original superó consistentemente al transformado, refuerza la decisión de mantener el modelo sin logaritmo como el más confiable.\n",
        "\n",
        "Sin embargo, es importante remarcar que el dataset cuenta con solo cinco años de información histórica (Enero 2020 a Diciembre 2024), lo cual resulta escaso frente a estimaciones que se expresan en escalas de cientos o incluso miles de meses. Esta limitación temporal reduce la capacidad del modelo para aprender patrones a largo plazo y afecta su fiabilidad cuando proyecta escenarios muy alejados en el tiempo.\n",
        "\n",
        "A pesar de la mejora en algunos indicadores puntuales, la transformación logarítmica no aportó beneficios generalizados al rendimiento del modelo. El modelo original de Random Forest, sin transformación, es el más robusto y balanceado para estimar la vida útil restante de los yacimientos de turba. No obstante, debe considerarse que la brevedad del histórico disponible condiciona la precisión de las estimaciones, especialmente en horizontes temporales largos.\n"
      ],
      "metadata": {
        "id": "oZjHJVVDBUjv"
      }
    }
  ]
}